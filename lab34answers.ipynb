{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b81a2a64-4925-49af-8b6a-e16d22886d42",
   "metadata": {},
   "source": [
    "## Labs 3 and 4\n",
    "### Data Engineering 1\n",
    "\n",
    "40 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb452059-1a14-4ce1-ae68-717c4177a47c",
   "metadata": {},
   "source": [
    "(1) Initialize a new project for this lab by following these steps:\n",
    "\n",
    "a. Create a new GitHub repository named \"Lab3and4\". Select the MIT license and choose a Python .gitignore file. Once the repository is created, edit the .gitignore file on the GitHub website, and add the following lines to the file:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96fa219c-eb84-4820-a4fe-70c18083cca5",
   "metadata": {},
   "source": [
    "#Data\n",
    "Country_Year_V-Dem_Core_CSV_v12/  \n",
    "ESGCountry.csv   \n",
    "ESGSeries-Time.csv  \n",
    "__MACOSX/                            \n",
    "ESGData.csv      \n",
    "ESGSeries.csv       \n",
    "ESGCountry-Series.csv            \n",
    "ESGFootNote.csv  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f1191a-4ee3-4ba0-b568-5ab8067ca4a7",
   "metadata": {},
   "source": [
    "This ensures that none of the data files are uploaded to your public GitHub repo (although the data are open, they have more restrictive licenses, and the best approach is to share code but not the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ff4d8-75b8-4ccb-893e-2d85a789e0b9",
   "metadata": {},
   "source": [
    "b. Use the `git clone` command to download the GitHub files into a folder on your computer. Then change the directory to be inside your local Lab3and4 folder. Next create four new files:\n",
    "\n",
    "    i. A requirements.txt file that loads jupyterlab==3.4.7, requests==2.28.1, pandas==1.5.1, numpy==1.23.4, psycopg2==2.9.5, and sqlalchemy==1.4.42 \n",
    "    \n",
    "    ii. A Dockerfile that loads a recent version of Python with the bulleye installation of Linux, copies the requirements.txt file into the image, runs commands to update pip and install the packages in requirements.txt, runs the commands to install nodejs and dbdocs, sets the working directory to /lab, exposes port 8888, and launches Jupyter lab. Use docker build to create an image from this Dockerfile.\n",
    "    \n",
    "    iii. A .env file that sets your POSTGRES_PASSWORD\n",
    "    \n",
    "    iv. A compose.yaml file that runs two services. First, it runs the postgres:latest image from Docker hub and supplies the .env file and maps port 5432 to your local 5432 port. Next run the image you created in (ii), supplying your .env file, mapping the 8888 port to a port on your comouter, and mapping the /lab directory to your local current working directory. Then define a network called postgresdata and make sure the postgres service maps the container's /var/lib/postgresql/data directory to this volume. Finally define a network named lab3network and set each service to use this network.\n",
    "\n",
    "Once you've created these files and run the `docker build` command, type `docker compose up` to launch your project environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a349fc-9d86-47f3-9d60-7d7c412cb116",
   "metadata": {},
   "source": [
    "(2) Load data and do pandas\n",
    "(3) Explain are tables 3rd NF and why\n",
    "(4) Send all data to postgres\n",
    "(5) Build ER diagram\n",
    "(6) Do SQL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
